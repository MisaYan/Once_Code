{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第 1 次迭代: [[10.75325608]]\n",
      "第 2 次迭代: [[-10.74230282]]\n",
      "第 3 次迭代: [[-12.55740652]]\n",
      "第 4 次迭代: [[-13.34753309]]\n",
      "第 5 次迭代: [[-13.83649208]]\n",
      "第 6 次迭代: [[-13.86602484]]\n",
      "第 7 次迭代: [[-13.88567585]]\n",
      "第 8 次迭代: [[-13.88601932]]\n",
      "第 9 次迭代: [[-13.88603251]]\n",
      "第 10 次迭代: [[-13.88603272]]\n",
      "conjugate gradient finished!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[-0.31704918],\n",
       "        [ 0.57577052],\n",
       "        [-0.13709436],\n",
       "        [ 0.11684474],\n",
       "        [ 0.10757077],\n",
       "        [ 0.1461028 ],\n",
       "        [-0.18187742],\n",
       "        [ 0.86721983],\n",
       "        [ 0.67423075],\n",
       "        [-0.24412747]]), array([[-13.88603272]]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#共轭梯度法\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def ConjugateGradient(A, x, b): \n",
    "    k = 0\n",
    "    r = b - np.dot(A,x)\n",
    "    d = r\n",
    "    \n",
    "    while True:   \n",
    "        k+=1\n",
    "        alpha = np.linalg.norm(r)**2 / np.vdot(np.dot(A,d),d)        \n",
    "        x = x + alpha * d\n",
    "        old_r = r\n",
    "        r = b - np.dot(A,x)\n",
    "        f = 1/2 * np.dot(np.dot(x.T,A),x) - np.dot(b.T, x) \n",
    "        print(\"第\",k,\"次迭代:\",f)\n",
    "        if np.linalg.norm(r) < 1e-6:\n",
    "            \n",
    "            print(\"conjugate gradient finished!\")\n",
    "            \n",
    "            return x,f\n",
    "            \n",
    "        else:\n",
    "            beta = np.linalg.norm(r)**2/np.linalg.norm(old_r)**2            \n",
    "            d = r + beta * d  \n",
    "        \n",
    "        \n",
    "           \n",
    "\n",
    "\n",
    "A = np.array([[ 56,   5,  -2,  12,   9,  -5, -10,  11,   1, -12],\n",
    "           [  5,  58,  -1,  10,   3, -11,  -4, -16, -17,   5],\n",
    "           [ -2,  -1,  67,   9,  10,  -4,  -6,   6,   6,  -1],\n",
    "           [ 12,  10,   9,  37,  22,   9,  15,  -1,   1, -9],\n",
    "           [  9,   3,  10,  22,  64,  -8,  -4, -11,   3,   0],\n",
    "           [ -5, -11,  -4,   9,  -8,  62,   4,   9,  -5,  -1],\n",
    "           [-10,  -4,  -6,  15,  -4,   4,  43,   4,   3,  -3],\n",
    "           [ 11, -16,   6,  -1, -11,   9,   4,  43, -16,  -3],\n",
    "           [  1, -17,   6,   1,   3,  -5,   3, -16,  61,   2],\n",
    "           [-12,   5,  -1,  -9,   0,  -1,  -3,  -3,   2,  57]])\n",
    "\n",
    "x = np.array([[1,1,1,1,1,1,1,1,1,1]]).T\n",
    "\n",
    "b = np.array([[2, 6, 3, 8, -1, 9, 2, 13, 15,-9]]).T\n",
    "\n",
    "ConjugateGradient(A, x, b)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第 1 次迭代: [[10.75325608]]\n",
      "第 2 次迭代: [[-8.86204433]]\n",
      "第 3 次迭代: [[-11.9095919]]\n",
      "第 4 次迭代: [[-12.72949547]]\n",
      "第 5 次迭代: [[-13.11738546]]\n",
      "第 6 次迭代: [[-13.36779043]]\n",
      "第 7 次迭代: [[-13.53433277]]\n",
      "第 8 次迭代: [[-13.64617809]]\n",
      "第 9 次迭代: [[-13.72172627]]\n",
      "第 10 次迭代: [[-13.77305921]]\n",
      "第 11 次迭代: [[-13.80809624]]\n",
      "第 12 次迭代: [[-13.83212001]]\n",
      "第 13 次迭代: [[-13.84864866]]\n",
      "第 14 次迭代: [[-13.86005925]]\n",
      "第 15 次迭代: [[-13.86795626]]\n",
      "第 16 次迭代: [[-13.87343501]]\n",
      "第 17 次迭代: [[-13.87724279]]\n",
      "第 18 次迭代: [[-13.87989382]]\n",
      "第 19 次迭代: [[-13.8817418]]\n",
      "第 20 次迭代: [[-13.88303153]]\n",
      "第 21 次迭代: [[-13.88393244]]\n",
      "第 22 次迭代: [[-13.88456225]]\n",
      "第 23 次迭代: [[-13.88500282]]\n",
      "第 24 次迭代: [[-13.88531117]]\n",
      "第 25 次迭代: [[-13.88552707]]\n",
      "第 26 次迭代: [[-13.88567829]]\n",
      "第 27 次迭代: [[-13.88578425]]\n",
      "第 28 次迭代: [[-13.88585851]]\n",
      "第 29 次迭代: [[-13.88591056]]\n",
      "第 30 次迭代: [[-13.88594705]]\n",
      "第 31 次迭代: [[-13.88597263]]\n",
      "第 32 次迭代: [[-13.88599058]]\n",
      "第 33 次迭代: [[-13.88600316]]\n",
      "第 34 次迭代: [[-13.88601198]]\n",
      "第 35 次迭代: [[-13.88601817]]\n",
      "第 36 次迭代: [[-13.88602251]]\n",
      "第 37 次迭代: [[-13.88602556]]\n",
      "第 38 次迭代: [[-13.8860277]]\n",
      "第 39 次迭代: [[-13.88602919]]\n",
      "第 40 次迭代: [[-13.88603025]]\n",
      "第 41 次迭代: [[-13.88603098]]\n",
      "第 42 次迭代: [[-13.8860315]]\n",
      "第 43 次迭代: [[-13.88603186]]\n",
      "第 44 次迭代: [[-13.88603212]]\n",
      "第 45 次迭代: [[-13.8860323]]\n",
      "第 46 次迭代: [[-13.88603242]]\n",
      "第 47 次迭代: [[-13.88603251]]\n",
      "第 48 次迭代: [[-13.88603257]]\n",
      "第 49 次迭代: [[-13.88603262]]\n",
      "第 50 次迭代: [[-13.88603265]]\n",
      "第 51 次迭代: [[-13.88603267]]\n",
      "第 52 次迭代: [[-13.88603268]]\n",
      "第 53 次迭代: [[-13.88603269]]\n",
      "第 54 次迭代: [[-13.8860327]]\n",
      "第 55 次迭代: [[-13.8860327]]\n",
      "第 56 次迭代: [[-13.88603271]]\n",
      "第 57 次迭代: [[-13.88603271]]\n",
      "第 58 次迭代: [[-13.88603271]]\n",
      "第 59 次迭代: [[-13.88603271]]\n",
      "第 60 次迭代: [[-13.88603271]]\n",
      "第 61 次迭代: [[-13.88603272]]\n",
      "第 62 次迭代: [[-13.88603272]]\n",
      "第 63 次迭代: [[-13.88603272]]\n",
      "第 64 次迭代: [[-13.88603272]]\n",
      "第 65 次迭代: [[-13.88603272]]\n",
      "第 66 次迭代: [[-13.88603272]]\n",
      "第 67 次迭代: [[-13.88603272]]\n",
      "第 68 次迭代: [[-13.88603272]]\n",
      "第 69 次迭代: [[-13.88603272]]\n",
      "第 70 次迭代: [[-13.88603272]]\n",
      "第 71 次迭代: [[-13.88603272]]\n",
      "Gradient Descent Fishend!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[-0.31704858],\n",
       "        [ 0.57577109],\n",
       "        [-0.13709404],\n",
       "        [ 0.11684237],\n",
       "        [ 0.10757146],\n",
       "        [ 0.14610353],\n",
       "        [-0.18187607],\n",
       "        [ 0.86721981],\n",
       "        [ 0.67423084],\n",
       "        [-0.24412767]]), array([[-13.88603272]]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#最速下降法\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def SteepestDescent(A, x, b):\n",
    "    k = 0\n",
    "    gradient = np.dot(A, x) - b\n",
    "    \n",
    "    while True:\n",
    "        k +=1\n",
    "        alpha = np.dot(gradient.T, gradient) / np.dot(np.dot(gradient.T, A), gradient)\n",
    "        old_x = x\n",
    "        x = old_x - alpha * gradient\n",
    "        gradient = np.dot(A, x) - b\n",
    "        f = 1/2 * np.dot(np.dot(x.T,A),x) - np.dot(b.T, x) \n",
    "        print(\"第\",k,\"次迭代:\",f)\n",
    "        \n",
    "        if np.linalg.norm(x - old_x) <1e-6:\n",
    "            print(\"Gradient Descent Fishend!\")\n",
    "            return x,f\n",
    "        \n",
    "A = np.array([[ 56,   5,  -2,  12,   9,  -5, -10,  11,   1, -12],\n",
    "           [  5,  58,  -1,  10,   3, -11,  -4, -16, -17,   5],\n",
    "           [ -2,  -1,  67,   9,  10,  -4,  -6,   6,   6,  -1],\n",
    "           [ 12,  10,   9,  37,  22,   9,  15,  -1,   1, -9],\n",
    "           [  9,   3,  10,  22,  64,  -8,  -4, -11,   3,   0],\n",
    "           [ -5, -11,  -4,   9,  -8,  62,   4,   9,  -5,  -1],\n",
    "           [-10,  -4,  -6,  15,  -4,   4,  43,   4,   3,  -3],\n",
    "           [ 11, -16,   6,  -1, -11,   9,   4,  43, -16,  -3],\n",
    "           [  1, -17,   6,   1,   3,  -5,   3, -16,  61,   2],\n",
    "           [-12,   5,  -1,  -9,   0,  -1,  -3,  -3,   2,  57]])\n",
    "\n",
    "x = np.array([[1,1,1,1,1,1,1,1,1,1]]).T\n",
    "\n",
    "b = np.array([[2, 6, 3, 8, -1, 9, 2, 13, 15,-9]]).T\n",
    "        \n",
    "SteepestDescent(A, x, b)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第 1 次迭代: [[-13.88603272]]\n",
      "第 2 次迭代: [[-13.88603272]]\n",
      "Gradient Descent Fishend!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[-0.31704918],\n",
       "        [ 0.57577052],\n",
       "        [-0.13709436],\n",
       "        [ 0.11684474],\n",
       "        [ 0.10757077],\n",
       "        [ 0.1461028 ],\n",
       "        [-0.18187742],\n",
       "        [ 0.86721983],\n",
       "        [ 0.67423075],\n",
       "        [-0.24412747]]), array([[-13.88603272]]))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#牛顿法\n",
    "import numpy as np\n",
    "from sympy import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def Newtown(A, x, b):\n",
    "    k = 0\n",
    "    gradient =  np.dot(A, x) - b\n",
    "    \n",
    "    while True:\n",
    "        k+=1        \n",
    "        old_x = x\n",
    "        x = old_x - np.dot(np.linalg.inv(A) , gradient)\n",
    "        gradient =  np.dot(A, x) - b\n",
    "        f = 1/2 * np.dot(np.dot(x.T,A),x) - np.dot(b.T, x) \n",
    "        print(\"第\",k,\"次迭代:\",f)\n",
    "        \n",
    "        if np.linalg.norm(x - old_x) < 1e-6:\n",
    "            print(\"Gradient Descent Fishend!\")\n",
    "            return x,f\n",
    "\n",
    "        \n",
    "A = np.array([[ 56,   5,  -2,  12,   9,  -5, -10,  11,   1, -12],\n",
    "           [  5,  58,  -1,  10,   3, -11,  -4, -16, -17,   5],\n",
    "           [ -2,  -1,  67,   9,  10,  -4,  -6,   6,   6,  -1],\n",
    "           [ 12,  10,   9,  37,  22,   9,  15,  -1,   1, -9],\n",
    "           [  9,   3,  10,  22,  64,  -8,  -4, -11,   3,   0],\n",
    "           [ -5, -11,  -4,   9,  -8,  62,   4,   9,  -5,  -1],\n",
    "           [-10,  -4,  -6,  15,  -4,   4,  43,   4,   3,  -3],\n",
    "           [ 11, -16,   6,  -1, -11,   9,   4,  43, -16,  -3],\n",
    "           [  1, -17,   6,   1,   3,  -5,   3, -16,  61,   2],\n",
    "           [-12,   5,  -1,  -9,   0,  -1,  -3,  -3,   2,  57]])\n",
    "\n",
    "x = np.array([[1111,1,1111,1,1,1,1111,1,1,1]]).T\n",
    "\n",
    "b = np.array([[2, 6, 3, 8, -1, 9, 2, 13, 15,-9]]).T\n",
    "\n",
    "Newtown(A, x, b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
